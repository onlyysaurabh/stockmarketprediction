# AI Analysis Service Configuration

# Google Gemini API Key (required for Gemini analyzer)
# Get this from Google AI Studio (https://ai.google.dev/)
GEMINI_API_KEY="your_gemini_api_key_here"

# vLLM API Configuration (required for vLLM analyzer)
# Base URL of the vLLM server's OpenAI-compatible API endpoint
VLLM_API_BASE_URL="http://localhost:8000/v1"

# Model name to use with vLLM
# Examples: "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Llama-3-8B-Instruct", etc.
VLLM_MODEL_NAME="Qwen/Qwen2.5-7B-Instruct"

# Groq API Configuration (required for Groq analyzer)
# Get this from Groq (https://console.groq.com/keys)
GROQ_API_KEY="your_groq_api_key_here"

# Model name to use with Groq
# Examples: "llama3-8b-8192", "llama3-70b-8192", "mixtral-8x7b-32768", etc.
GROQ_MODEL_NAME="llama3-8b-8192"

# Default AI Analyzer to use (options: 'gemini', 'vllm', or 'groq')
DEFAULT_AI_ANALYZER="gemini"
